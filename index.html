<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="AdaptiveDiffusion">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>OmniCaptioner</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <style>
    .layout-wrapper {
      display: flex;
      gap: 20px;
      min-height: 500px;
    }

    .sidebar {
        width: 170px;
        background-color: #f1f1f1;
        padding: 20px;
    }
    .sidebar ul {
        list-style: none;
    }
    .sidebar li {
        padding: 10px;
        margin: 5px 0;
        cursor: pointer;
        border-radius: 5px;
        transition: background-color 0.3s;
    }
    .sidebar li:hover {
        background-color: #ddd;
    }
    .sidebar li.active {
        background-color: #4CAF50;
        color: white;
    }
    .content {
        flex: 1;
        padding: 10px;
    }
    .content-section {
        display: none;
    }
    .content-section.active {
        display: block;
    }
    .content img {
      max-width: 100%;
      height: auto;
      display: block;
      margin: 0 auto;
    }
  </style>
</head>
<body>

<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title" style="font-size: 2.5rem">
                        <!-- <img src="static/images/apple-touch-icon.png" style="width: 40pt"> -->
                        GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling
                    </h1>
                    <div class="is-size-5 publication-authors">
                        <!-- Paper authors -->
                        <span class="author-block">
                            <a href="" target="_blank">Siqi Li</a><sup>1,2</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Yufan Shen</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Xiangnan Chen</a><sup>1,2</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Jiayi Chen</a><sup>3</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Hengwei Ju</a><sup>1,4</sup>,</span>
                        <br>
                        <span class="author-block">
                            <a href="" target="_blank">Haodong Duan</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">SongMao</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Hongbin Zhou</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Bo Zhang</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Bin Fu</a><sup>1</sup>,</span>
                        <br>
                        <span class="author-block">
                            <a href="" target="_blank">Pinlong Cai</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Licheng Wen</a><sup>1</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Botian Shi</a><sup>1,5</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Yong Liu</a><sup>2,‚Ä†</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Xinyu Cai</a><sup>1,‚àó,‚Ä†</sup>,</span>
                        <span class="author-block">
                            <a href="" target="_blank">Yu Qiao</a><sup>1</sup>
                        </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block">
                            <sup>1</sup>Shanghai Artificial Intelligence Laboratory
                            <sup>2</sup>Zhejiang University <br>
                            <sup>3</sup>School of Science and Engineering, The Chinese University of Hong Kong <br>
                            <sup>4</sup>Fudan University 
                            <sup>5</sup>Shanghai Innovation Institute
                        </span>
                        <span class="eql-cntrb" style="font-size:15pt"><br><sup>‚Ä†</sup>Corresponding author, <sup>*</sup>Project Leader</span>
                    </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.00063" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Arxiv</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/Alpha-Innovator/OmniCaptioner" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <span class="link-block">
                  <a href="https://huggingface.co/GDIBench/GDI-Model" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-download"></i>
                  </span>
                  <span>Model</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://huggingface.co/datasets/GDIBench/GDI-Bench" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-download"></i>
                  </span>
                <span>Dataset</span>
                </a>
              </span>

                <!-- ArXiv abstract Link -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h4 class="subtitle">
        üî•<span style="color: #ff3860">[NEW!]</span>
        GDI-Bench is a document-domain benchmark with a difficulty grading system that decouples visual and reasoning complexity for systematic model evaluation and optimization. <br>
        üî•<span style="color: #ff3860">[NEW!]</span>
        GDI-Model is 8B-sized model that demonstrates strong general performance in the domain of document processing. <br>
        üî•<span style="color: #ff3860">[NEW!]</span>
        <a href="https://huggingface.co/datasets/GDIBench/GDI-Bench">Dataset</a> & <a href="https://huggingface.co/GDIBench/GDI-Model">Model</a> have been released!
      </h4>
    </div>
  </div>
</section>

<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<section class="hero is-small">
  <div class="hero-body">
    <div class="container", style="max-width: 1200px">
       <div class="item">
        <!-- <h2 class="subtitle has-text-centered", style="font-size: 1.5rem; font-weight: bolder">
          Different prompts may require different steps of noise prediction!!!
        </h2> -->
        <!-- Your image here -->
        <img src="static/images/20250528-155238.jpg" alt="GDI-Bench Overview" style="max-width: 90%; height: auto; margin: 0 auto; display: block;"/>
        <h2 class="subtitle has-text-centered", style="font-size: 1rem">
          GDI-Bench: The benchmark decouples document understanding complexity into visual complexity (V0-V2) and reasoning complexity (R0-R2) dimensions, creating a comprehensive evaluation framework for assessing MLLMs' capabilities across various document types and reasoning tasks. Queries marked with a ‚ÄúCN‚Äù tag originate in Chinese and have been translated into English using Google Translate.
        </h2>
      </div>
  </div>
</div>
</section>


<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The rapid advancement of multimodal large language models (MLLMs) has profoundly impacted the document domain, creating a wide array of application scenarios. This progress highlights the need for a comprehensive benchmark to evaluate these models' capabilities across various document-specific tasks. However, existing benchmarks often fail to locate specific model weaknesses or guide systematic improvements. To bridge this gap, we introduce a General Document Intelligence Benchmark (GDI-Bench), featuring 2.3k images across 9 key scenarios and 19 document-specific tasks. By decoupling visual complexity and reasoning complexity, the GDI-Bench structures graded tasks that allow performance assessment by difficulty, aiding in model weakness identification and optimization guidance. We evaluate various open-source and closed-source models on GDI-Bench, conducting decoupled analyses in the visual and reasoning domains, revealing their strengths and weaknesses. To address the diverse tasks and domains in the GDI-Bench, we propose a GDI-Model that mitigates catastrophic forgetting during the supervised fine-tuning (SFT) process through an intelligence-preserving training strategy, thereby reinforcing the inherent weaknesses of the base model. Our model achieves state-of-the-art performance on previous benchmarks and the GDI-Bench. Both our benchmark and models are or will be open-sourced on https://huggingface.co/GDIBench.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper Method -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div style="width: 100%;">
        <h2 class="title is-3">GDI-Bench and GDI-Model</h2>
        <div class="content has-text-justified">
          <p style="font-size: 1.2rem; font-weight: bolder">
            To assist Multimodal Large Language Models (MLLMs) in locating their weaknesses within the document domain and to further guide model optimization, we first constructed a benchmark. GDI-Bench decouples task complexity into two distinct dimensions‚Äîvisual complexity and reasoning complexity‚Äîand establishes a graded mechanism.
          </p>
          <p>
            <img src="static/images/v-r.jpg" alt="MY ALT TEXT" style="margin-top: 15pt; width: 50%; margin: 0 auto;"/>
            <h2 class="subtitle has-text-centered", style="font-size: 1rem; font-weight: 100;">
              Complexity Distribution in the GDI Benchmark. The visual complexity dimension is operationalized through a hierarchical categorization of document images into three levels: V0 (plain text), V1 (formal representations), and V2 (explanatory representations). In parallel, the dimension of reasoning complexity is characterized by three categories: R0 (Full Page Structured Extraction), R1 (Information Extraction), and R2 (Reasoning).
            </h2> 
          </p>
          <p style="font-size: 1.2rem; font-weight: bolder; margin-top: 30pt">
            After using GDI-Bench to identify the model's weaknesses, we employed the supervised fine-tuning (SFT) to enhance the model's performance. To address the catastrophic forgetting issue caused by SFT, we propose the Layer-wise Adaptive Freezing-Tuning (LW-AFT) method.
          </p>
          <p>
            <img src="static/images/Freeze.drawio.png" alt="MY ALT TEXT" style="margin-top: 15pt; width: 95%; margin-left: 5%;"/>
            <h2 class="subtitle has-text-centered", style="font-size: 1rem; font-weight: 100;">
              Overview of the Layer-wise Adaptive Freeze-Tuning method. The LW-AFT method freezes the majority of the model's parameters to preserve its general capabilities. It utilizes a specialized expert model, fine-tuned on a small subset of the dataset, to guide the freezing of parameters in each layer of the original model during the SFT process. Only domain-specific parameters are updated, thereby achieving efficient fine-tuning.
            </h2> 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper Method -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="static/images/Dolphin_video_720.mp4" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen autoplay></iframe> -->
            <!-- <video width="640" height="360" autoplay mute loop controls>
              <source src="static/images/Dolphin_video_720.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->

<!-- Paper Experiment -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div style="width: 100%;">
        <h2 class="title is-3">Experiments</h2>
        <div class="content has-text-justified">
          <p>
            <img src="static/images/multiple_datasets.jpg" alt="MY ALT TEXT" style="margin-top: 20pt; width: 95%; margin-left: 5%;"/>
          <h2 class="subtitle has-text-centered", style="font-size: 1rem; font-weight: 100">
            The performance of different training methods on multiple datasets.
          </h2> 
          </p>
          <p>
            <img src="static/images/multi_subplot_analysis_alpha.png" alt="MY ALT TEXT" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
            <h2 class="subtitle has-text-centered", style="font-size: 1rem; font-weight: 100">
              Performance of various open-source and closed-source models on GDI-Bench at different levels of reasoning complexity. The GDI-Model is fine-tuned based on the InternVL3-8B model.
            </h2> 
          </p>
          <p>
            <img src="static/images/20250528-155610.jpg" alt="MY ALT TEXT" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
            <h2 class="subtitle has-text-centered", style="font-size: 1rem; font-weight: 100">
              The performance of different open-source and closed-source large models and different training methods on GDI-Bench.
            </h2> 
          </p>
          <!-- <p>
            <img src="static/images/llm_mllm.png" alt="MY ALT TEXT" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
            <h2 class="subtitle has-text-centered", style="font-size: 1rem; font-weight: 100">
              Performance comparison across various benchmarks for different LLMs/MLLMs (7B), with or without visual input.
            </h2> 
          </p> -->
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper Experiment -->

<section class="hero is-small">
  <div class="hero-body">
    <h2 class="title is-3" style="justify-self: center">Case Study !</h2>
    <div class="container", style="max-width: 1200px">
      <div class="layout-wrapper">
      <div class="sidebar">
        <ul>
            <li class="active" data-section="section1">Table Extraction</li>
            <li data-section="section2">Newspaper Title Extraction</li>
            <li data-section="section3">Question Extraction by Test Point</li>
            <li data-section="section4">Question Extraction by Question Number</li>
            <li data-section="section5">Author Extraction</li>
            <li data-section="section6">Table QA</li>
            <li data-section="section7">Chart Extraction</li>
        </ul>
    </div>
    <div class="content">
      <div id="section1" class="content-section active">
        <img src="static/images/case1.png" alt="Table Extraction" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
      </div>
      
      <div id="section2" class="content-section">
        <img src="static/images/case2.png" alt="Newspaper Title Extraction" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
      </div>
      
      <div id="section3" class="content-section">
        <img src="static/images/case3.png" alt="Question Extraction by Test Point" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
      </div>
      
      <div id="section4" class="content-section">
        <img src="static/images/case4.png" alt="Question Extraction by Question Number" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
      </div>

      <div id="section5" class="content-section">
        <img src="static/images/case5.png" alt="Author Extraction" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
      </div>

      <div id="section6" class="content-section">
        <img src="static/images/case6.png" alt="Table QA" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
      </div>

      <div id="section7" class="content-section">
        <img src="static/images/case7.png" alt="Chart Extraction" style="margin-top: 20pt; width: 90%; margin-left: 5%;"/>
      </div>
  </div>
  </div>
</div>
</div>
<script>
  document.querySelectorAll('.sidebar li').forEach(item => {
      item.addEventListener('click', function() {
          // ÁßªÈô§ÊâÄÊúâÊ¥ªÂä®Áä∂ÊÄÅ
          document.querySelectorAll('.sidebar li').forEach(i => i.classList.remove('active'));
          document.querySelectorAll('.content-section').forEach(section => section.classList.remove('active'));
          
          // Ê∑ªÂä†Êñ∞ÁöÑÊ¥ªÂä®Áä∂ÊÄÅ
          this.classList.add('active');
          const sectionId = this.getAttribute('data-section');
          document.getElementById(sectionId).classList.add('active');
      });
  });
</script>
</section>

<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.png" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code> -->
        <!-- @article{ye2024training,
          title={Training-Free Adaptive Diffusion with Bounded Difference Approximation Strategy},
          author={Ye, Hancheng and Yuan, Jiakang and Xia, Renqiu and Yan, Xiangchao and Chen, Tao and Yan, Junchi and Shi, Botian and Zhang, Bo},
          journal={Advances in Neural Information Processing Systems},
          volume={36},
          year={2024}
        } -->
      <!-- </code></pre>
    </div>
</section> -->
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
